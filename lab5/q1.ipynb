{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316c101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences available: 1631\n"
     ]
    }
   ],
   "source": [
    "# Setup: imports and data load\n",
    "import json, random\n",
    "from typing import List, Tuple, Dict\n",
    "from collections import Counter, defaultdict\n",
    "from math import log\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# Load tokenized dataset produced in lab1\n",
    "with open('../lab1/gujarati_corpus_tokenized.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract sentences as token lists (keep punctuation as tokens)\n",
    "all_sentences_tokens: List[List[str]] = []\n",
    "for doc in data:\n",
    "    for s in doc.get('sentences', []):\n",
    "        tokens = s.get('words', [])\n",
    "        if tokens:\n",
    "            all_sentences_tokens.append(tokens)\n",
    "\n",
    "print(f\"Total sentences available: {len(all_sentences_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91149dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes -> train: 1431, val: 100, test: 100\n"
     ]
    }
   ],
   "source": [
    "# Create 100/100/remaining splits (validation/test/training)\n",
    "num_sentences = len(all_sentences_tokens)\n",
    "indices = list(range(num_sentences))\n",
    "random.shuffle(indices)\n",
    "\n",
    "val_size = min(100, num_sentences)\n",
    "test_size = min(100, max(0, num_sentences - val_size))\n",
    "\n",
    "val_idx = set(indices[:val_size])\n",
    "test_idx = set(indices[val_size:val_size + test_size])\n",
    "\n",
    "val_set = [all_sentences_tokens[i] for i in val_idx]\n",
    "test_set = [all_sentences_tokens[i] for i in test_idx]\n",
    "train_set = [all_sentences_tokens[i] for i in indices if i not in val_idx and i not in test_idx]\n",
    "\n",
    "print(f\"Split sizes -> train: {len(train_set)}, val: {len(val_set)}, test: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eed3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram counting helpers (BOS/EOS markers)\n",
    "from typing import Iterable\n",
    "\n",
    "def add_markers(sent: List[str], n: int) -> List[str]:\n",
    "    return ['<s>'] * (n-1) + sent + ['</s>']\n",
    "\n",
    "def extract_ngrams(sent: List[str], n: int) -> Iterable[Tuple[str, ...]]:\n",
    "    tokens = add_markers(sent, n)\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        yield tuple(tokens[i:i+n])\n",
    "\n",
    "def build_ngram_counts(sentences: List[List[str]], n: int):\n",
    "    ngram_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "    vocab = set()\n",
    "    for sent in sentences:\n",
    "        vocab.update(sent)\n",
    "        for ng in extract_ngrams(sent, n):\n",
    "            ngram_counts[ng] += 1\n",
    "            if n > 1:\n",
    "                context_counts[ng[:-1]] += 1\n",
    "    # include markers in vocab\n",
    "    vocab.update({'<s>', '</s>'})\n",
    "    return ngram_counts, context_counts, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ec7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good-Turing smoothing utilities\n",
    "\n",
    "def compute_Nc(ngram_counts: Counter) -> Dict[int, int]:\n",
    "    Nc = Counter()\n",
    "    for _, c in ngram_counts.items():\n",
    "        Nc[c] += 1\n",
    "    return Nc\n",
    "\n",
    "class GoodTuringModel:\n",
    "    def __init__(self, n: int, ngram_counts: Counter, context_counts: Counter, vocab: set):\n",
    "        self.n = n\n",
    "        self.ngram_counts = ngram_counts\n",
    "        self.context_counts = context_counts\n",
    "        self.vocab = vocab\n",
    "        self.V = len(vocab)\n",
    "        self.N = sum(ngram_counts.values())  # total seen n-gram tokens\n",
    "        self.unique_seen = len(ngram_counts) # number of distinct seen n-grams\n",
    "        self.Nc = compute_Nc(ngram_counts)\n",
    "        self.N1 = self.Nc.get(1, 0)\n",
    "        # Space of all possible n-grams\n",
    "        if n == 1:\n",
    "            self.total_possible = self.V\n",
    "            self.unseen_possible = self.V - self.unique_seen\n",
    "        else:\n",
    "            self.total_possible = self.V ** n\n",
    "            self.unseen_possible = max(0, self.total_possible - self.unique_seen)\n",
    "        # Cumulative mass for unseen\n",
    "        self.mass_unseen = (self.N1 / self.N) if self.N > 0 else 0.0\n",
    "        # Per unseen n-gram probability\n",
    "        self.P_unseen = (self.mass_unseen / self.unseen_possible) if self.unseen_possible > 0 else 0.0\n",
    "\n",
    "    def adjusted_count(self, c: int) -> float:\n",
    "        # Good-Turing adjusted count c* = (c+1) * N_{c+1} / N_c\n",
    "        if c == 0:\n",
    "            return self.mass_unseen  # distribute later as probability\n",
    "        Nc = self.Nc.get(c, 0)\n",
    "        Ncp1 = self.Nc.get(c+1, 0)\n",
    "        if Nc == 0:\n",
    "            return c  # fallback to MLE if no neighbor counts\n",
    "        return (c + 1) * (Ncp1 / Nc)\n",
    "\n",
    "    def ngram_probability(self, ngram: Tuple[str, ...]) -> float:\n",
    "        c = self.ngram_counts.get(ngram, 0)\n",
    "        if c == 0:\n",
    "            return self.P_unseen\n",
    "        c_star = self.adjusted_count(c)\n",
    "        # For conditional models (n>=2), normalize by context count; for unigram by N\n",
    "        if self.n == 1:\n",
    "            return c_star / self.N\n",
    "        else:\n",
    "            context = ngram[:-1]\n",
    "            context_count = self.context_counts.get(context, 0)\n",
    "            # If context never seen, back off to unigram-like unseen per space\n",
    "            if context_count == 0:\n",
    "                return self.P_unseen\n",
    "            # Scale c* to probability roughly as MLE replacement\n",
    "            return c_star / context_count\n",
    "\n",
    "    def sentence_logprob(self, sentence: List[str]) -> float:\n",
    "        tokens = ['<s>'] * (self.n - 1) + sentence + ['</s>']\n",
    "        lp = 0.0\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            ng = tuple(tokens[i:i+self.n])\n",
    "            p = self.ngram_probability(ng)\n",
    "            if p <= 0:\n",
    "                return float('-inf')\n",
    "            lp += log(p)\n",
    "        return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b47a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1: seen n-grams=7700, tokens=21944, V=7701; N1=5339, unseen_possible≈1\n",
      "n=2: seen n-grams=17692, tokens=21944, V=7701; N1=16254, unseen_possible≈59287709\n",
      "n=3: seen n-grams=20282, tokens=21944, V=7701; N1=19573, unseen_possible≈456710872819\n",
      "n=4: seen n-grams=21026, tokens=21944, V=7701; N1=20625, unseen_possible≈3517130587749775\n",
      "\n",
      "Perplexities on val set:\n",
      "  1-gram GT perplexity: inf\n",
      "  2-gram GT perplexity: inf\n",
      "  3-gram GT perplexity: inf\n",
      "  4-gram GT perplexity: inf\n",
      "\n",
      "Perplexities on test set:\n",
      "  1-gram GT perplexity: inf\n",
      "  2-gram GT perplexity: inf\n",
      "  3-gram GT perplexity: inf\n",
      "  4-gram GT perplexity: inf\n"
     ]
    }
   ],
   "source": [
    "# Build counts for n=1..4 on training set and init GT models\n",
    "orders = [1,2,3,4]\n",
    "counts = {}\n",
    "models_gt = {}\n",
    "for n in orders:\n",
    "    ng_counts, ctx_counts, vocab = build_ngram_counts(train_set, n)\n",
    "    counts[n] = (ng_counts, ctx_counts, vocab)\n",
    "    models_gt[n] = GoodTuringModel(n, ng_counts, ctx_counts, vocab)\n",
    "    print(f\"n={n}: seen n-grams={len(ng_counts)}, tokens={sum(ng_counts.values())}, V={len(vocab)}; N1={models_gt[n].N1}, unseen_possible≈{models_gt[n].unseen_possible}\")\n",
    "\n",
    "# Helper to compute corpus perplexity\n",
    "def corpus_perplexity(model: GoodTuringModel, corpus: List[List[str]]) -> float:\n",
    "    total_logprob = 0.0\n",
    "    total_tokens = 0\n",
    "    for sent in corpus:\n",
    "        lp = model.sentence_logprob(sent)\n",
    "        if lp == float('-inf'):\n",
    "            return float('inf')\n",
    "        total_logprob += lp\n",
    "        total_tokens += len(sent) + 1  # include </s>\n",
    "    if total_tokens == 0:\n",
    "        return float('inf')\n",
    "    avg_logprob = total_logprob / total_tokens\n",
    "    # natural log perplexity\n",
    "    return pow(2.718281828, -avg_logprob)\n",
    "\n",
    "# Evaluate on validation and test\n",
    "for split_name, split in [('val', val_set), ('test', test_set)]:\n",
    "    print(f\"\\nPerplexities on {split_name} set:\")\n",
    "    for n in orders:\n",
    "        ppl = corpus_perplexity(models_gt[n], split)\n",
    "        print(f\"  {n}-gram GT perplexity: {ppl:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc3f450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 for 1-gram:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>C</th>\n",
       "      <th>Nc</th>\n",
       "      <th>C*</th>\n",
       "      <th>P_MLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>1431</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>છે</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>અને</td>\n",
       "      <td>387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>આ</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>કે</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>પણ</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>માટે</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>કરી</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ngram     C  Nc   C*     P_MLE\n",
       "0  </s>  1431   1  0.0  0.065211\n",
       "1    છે   808   1  0.0  0.036821\n",
       "2     ,   762   1  0.0  0.034725\n",
       "3   અને   387   1  0.0  0.017636\n",
       "4     આ   241   1  0.0  0.010983\n",
       "5    કે   193   1  0.0  0.008795\n",
       "6    પણ   189   1  0.0  0.008613\n",
       "7  માટે   177   1  0.0  0.008066\n",
       "8     -   150   1  0.0  0.006836\n",
       "9   કરી   126   1  0.0  0.005742"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 for 2-gram:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>C</th>\n",
       "      <th>Nc</th>\n",
       "      <th>C*</th>\n",
       "      <th>P_MLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>છે &lt;/s&gt;</td>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.644802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; આ</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>છે ,</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>હતી &lt;/s&gt;</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>હતો &lt;/s&gt;</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>છે કે</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>કે ,</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>હતા &lt;/s&gt;</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>કરે છે</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>છે અને</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.045792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ngram    C  Nc    C*     P_MLE\n",
       "0   છે </s>  521   1   0.0  0.644802\n",
       "1     <s> આ  107   1   0.0  0.074773\n",
       "2      છે ,   99   1   0.0  0.122525\n",
       "3  હતી </s>   71   1   0.0  0.717172\n",
       "4  હતો </s>   57   1   0.0  0.740260\n",
       "5     છે કે   51   1   0.0  0.063119\n",
       "6      કે ,   45   1   0.0  0.233161\n",
       "7  હતા </s>   42   1   0.0  0.724138\n",
       "8    કરે છે   38   1   0.0  0.883721\n",
       "9    છે અને   37   1  38.0  0.045792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 for 3-gram:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>C</th>\n",
       "      <th>Nc</th>\n",
       "      <th>C*</th>\n",
       "      <th>P_MLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; આ</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>શકે છે &lt;/s&gt;</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>કરે છે &lt;/s&gt;</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>આવી છે &lt;/s&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; જો</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.013976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>આવે છે &lt;/s&gt;</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; એક</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; પરંતુ</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.010482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>થાય છે &lt;/s&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>રહી છે &lt;/s&gt;</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ngram    C  Nc         C*     P_MLE\n",
       "0      <s> <s> આ  107   1   0.000000  0.074773\n",
       "1    શકે છે </s>   28   1   0.000000  0.777778\n",
       "2    કરે છે </s>   24   1   0.000000  0.631579\n",
       "3    આવી છે </s>   21   1   0.000000  0.840000\n",
       "4     <s> <s> જો   20   1  21.000000  0.013976\n",
       "5    આવે છે </s>   19   1  20.000000  0.575758\n",
       "6     <s> <s> એક   16   1   0.000000  0.011181\n",
       "7  <s> <s> પરંતુ   15   3   5.333333  0.010482\n",
       "8    થાય છે </s>   15   3   5.333333  0.789474\n",
       "9    રહી છે </s>   15   3   5.333333  0.937500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 for 4-gram:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>C</th>\n",
       "      <th>Nc</th>\n",
       "      <th>C*</th>\n",
       "      <th>P_MLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; આ</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; જો</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; એક</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; પરંતુ</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.010482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; તે</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.009783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; જોકે</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.009085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>કરી શકે છે &lt;/s&gt;</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>કરવામાં આવી છે &lt;/s&gt;</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; ત્યારે</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.007687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;s&gt; &lt;s&gt; &lt;s&gt; જ્યારે</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.007687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ngram    C  Nc    C*     P_MLE\n",
       "0        <s> <s> <s> આ  107   1   0.0  0.074773\n",
       "1       <s> <s> <s> જો   20   1   0.0  0.013976\n",
       "2       <s> <s> <s> એક   16   1   0.0  0.011181\n",
       "3    <s> <s> <s> પરંતુ   15   1  16.0  0.010482\n",
       "4       <s> <s> <s> તે   14   1  15.0  0.009783\n",
       "5     <s> <s> <s> જોકે   13   1  14.0  0.009085\n",
       "6      કરી શકે છે </s>   12   2   6.5  0.857143\n",
       "7  કરવામાં આવી છે </s>   12   2   6.5  0.923077\n",
       "8   <s> <s> <s> ત્યારે   11   2  12.0  0.007687\n",
       "9   <s> <s> <s> જ્યારે   11   2  12.0  0.007687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top-100 frequency tables: C, Nc, C*, P_MLE\n",
    "import pandas as pd\n",
    "\n",
    "freq_tables = {}\n",
    "for n in orders:\n",
    "    ng_counts, ctx_counts, _ = counts[n]\n",
    "    gt = models_gt[n]\n",
    "    rows = []\n",
    "    for ng, c in ng_counts.most_common(100):\n",
    "        Nc = gt.Nc.get(c, 0)\n",
    "        c_star = gt.adjusted_count(c)\n",
    "        if n == 1:\n",
    "            p_mle = c / gt.N if gt.N > 0 else 0\n",
    "        else:\n",
    "            ctx = ng[:-1]\n",
    "            denom = ctx_counts.get(ctx, 0)\n",
    "            p_mle = c / denom if denom > 0 else 0\n",
    "        rows.append({\n",
    "            'ngram': ' '.join(ng),\n",
    "            'C': c,\n",
    "            'Nc': Nc,\n",
    "            'C*': c_star,\n",
    "            'P_MLE': p_mle\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    freq_tables[n] = df\n",
    "    print(f\"\\nTop 10 for {n}-gram:\")\n",
    "    display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2349beea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambdas (val): (0.3, 0.2, 0.2, 0.30000000000000004), perplexity: 2217.563\n",
      "Test perplexity with best lambdas: 1860.701\n"
     ]
    }
   ],
   "source": [
    "# Deleted interpolation for 4-gram (Jelinek-Mercer style)\n",
    "import numpy as np\n",
    "\n",
    "# Prepare counts for 1..4\n",
    "ng1, ctx1, V1 = counts[1]\n",
    "ng2, ctx2, V2 = counts[2]\n",
    "ng3, ctx3, V3 = counts[3]\n",
    "ng4, ctx4, V4 = counts[4]\n",
    "\n",
    "# Helper to get MLE conditional probabilities with add-epsilon for stability\n",
    "def mle_prob(ng_counts, ctx_counts, ngram, eps=0.0, V=len(V4)):\n",
    "    c = ng_counts.get(ngram, 0)\n",
    "    if len(ngram) == 1:\n",
    "        total = sum(ng_counts.values())\n",
    "        return (c + eps) / (total + eps*V)\n",
    "    ctx = ngram[:-1]\n",
    "    denom = ctx_counts.get(ctx, 0) + eps*V\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return (c + eps) / denom\n",
    "\n",
    "# Score sentence with interpolation lambdas\n",
    "def interp_sentence_logprob(sentence, lambdas):\n",
    "    l1,l2,l3,l4 = lambdas\n",
    "    tokens = ['<s>']*3 + sentence + ['</s>']\n",
    "    lp = 0.0\n",
    "    for i in range(3, len(tokens)):\n",
    "        w1,w2,w3,w4 = tokens[i-3:i+1]\n",
    "        p1 = mle_prob(ng1, ctx1, (w4,), eps=1e-8, V=len(V1))\n",
    "        p2 = mle_prob(ng2, ctx2, (w3,w4), eps=1e-8, V=len(V2))\n",
    "        p3 = mle_prob(ng3, ctx3, (w2,w3,w4), eps=1e-8, V=len(V3))\n",
    "        p4 = mle_prob(ng4, ctx4, (w1,w2,w3,w4), eps=1e-8, V=len(V4))\n",
    "        p = l1*p1 + l2*p2 + l3*p3 + l4*p4\n",
    "        if p <= 0:\n",
    "            return float('-inf')\n",
    "        lp += log(p)\n",
    "    return lp\n",
    "\n",
    "# Simple grid search for lambdas that sum to 1\n",
    "candidates = []\n",
    "vals = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for l1 in vals:\n",
    "    for l2 in vals:\n",
    "        for l3 in vals:\n",
    "            l4 = 1.0 - (l1+l2+l3)\n",
    "            if l4 < -1e-9:\n",
    "                continue\n",
    "            if l4 < 0: l4 = 0.0\n",
    "            candidates.append((l1,l2,l3,l4))\n",
    "\n",
    "# Evaluate on validation set\n",
    "best_lambdas = None\n",
    "best_ppl = float('inf')\n",
    "\n",
    "for lambdas in candidates:\n",
    "    total_logprob = 0.0\n",
    "    total_tokens = 0\n",
    "    for sent in val_set:\n",
    "        lp = interp_sentence_logprob(sent, lambdas)\n",
    "        if lp == float('-inf'):\n",
    "            total_logprob = float('-inf'); break\n",
    "        total_logprob += lp\n",
    "        total_tokens += len(sent) + 1\n",
    "    if total_logprob == float('-inf') or total_tokens == 0:\n",
    "        ppl = float('inf')\n",
    "    else:\n",
    "        avg = total_logprob/total_tokens\n",
    "        ppl = pow(2.718281828, -avg)\n",
    "    if ppl < best_ppl:\n",
    "        best_ppl = ppl\n",
    "        best_lambdas = lambdas\n",
    "\n",
    "print(f\"Best lambdas (val): {best_lambdas}, perplexity: {best_ppl:.3f}\")\n",
    "\n",
    "# Evaluate best on test\n",
    "if best_lambdas is not None:\n",
    "    total_logprob = 0.0\n",
    "    total_tokens = 0\n",
    "    for sent in test_set:\n",
    "        lp = interp_sentence_logprob(sent, best_lambdas)\n",
    "        if lp == float('-inf'):\n",
    "            total_logprob = float('-inf'); break\n",
    "        total_logprob += lp\n",
    "        total_tokens += len(sent) + 1\n",
    "    test_ppl = float('inf') if (total_logprob == float('-inf') or total_tokens==0) else pow(2.718281828, -(total_logprob/total_tokens))\n",
    "    print(f\"Test perplexity with best lambdas: {test_ppl:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
